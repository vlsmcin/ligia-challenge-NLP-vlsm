# ligia-challenge-NLP-vlsm

<a target="_blank" href="https://cookiecutter-data-science.drivendata.org/">
    <img src="https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter" />
</a>

Projeto de classificaÃ§Ã£o de textos para detecÃ§Ã£o de desinformaÃ§Ã£o digital. O objetivo Ã© desenvolver e avaliar modelos de NLP capazes de distinguir notÃ­cias legÃ­timas de conteÃºdos falsos com base em padrÃµes linguÃ­sticos e semÃ¢nticos. O projeto foi desenvolvido como parte da segunda etapa do processo seletivo da Liga AcadÃªmica de Inteligáº½ncia Artificial da UFPE.

## ğŸ“¦ PrÃ©-requisitos

- Python 3.12+
- Conda (Anaconda ou Miniconda)

---

## âš™ï¸ Setup do ambiente

### 1. Criar o ambiente virtual

```bash
conda create -n ligia-challenge-NLP python=3.12
```

### 2. Ativar o ambiente

```bash
conda activate ligia-challenge-NLP
```

### 3. Instalar as dependÃªncias

```bash
python -m pip install -r requirements.txt
```

## Project Organization

```
â”œâ”€â”€ LICENSE            <- Open-source license
â”œâ”€â”€ Makefile           <- Makefile with convenience commands like `make data` or `make train`
â”œâ”€â”€ README.md          <- The top-level README for developers using this project.
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ processed      <- The final, canonical data sets for modeling.
â”‚   â””â”€â”€ raw            <- The original, immutable data dump.
â”‚
â”‚
â”œâ”€â”€ models             <- Trained and serialized models, model predictions, or model summaries
â”‚
â”œâ”€â”€ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
â”‚                         the creator's initials, and a short `-` delimited description, e.g.
â”‚                         `1.0-jqp-initial-data-exploration`.
â”‚
â”œâ”€â”€ scripts            <- Scripts executaveis para pre-processamento e treino
â”‚   â”œâ”€â”€ preprocessing.py <- Gera matrizes em data/processed e salva vetorizadores
â”‚   â””â”€â”€ training.py     <- Treina o modelo final e salva models/best_model.joblib
â”‚
â”œâ”€â”€ pyproject.toml     <- Project configuration file with package metadata for 
â”‚                         src and configuration for tools like black
â”‚
â”‚
â”œâ”€â”€ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
â”‚                         generated with `pip freeze > requirements.txt`
â”‚
â”‚
â””â”€â”€ src   <- Source code for use in this project.
    â”‚
    â””â”€â”€ __init__.py             <- Makes src a Python module
```

## ğŸ§ª Como executar

### 1. Gerar dados processados

```bash
python scripts/preprocessing.py
```

Ou usando make:

```bash
make preprocess
```

### 2. Treinar modelo final

```bash
python scripts/training.py
```

Ou usando make:

```bash
make train
```

O modelo treinado sera salvo em `models/best_model.joblib`.

--------

